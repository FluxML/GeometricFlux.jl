"""
    AbstractPositionalEncoding

Abstract type of positional encoding for GNN.
"""
abstract type AbstractPositionalEncoding end

"""
    RandomWalkPE{K}

Concrete type of positional encoding from random walk method.

See also [`positional_encode`](@ref) for generating positional encoding.
"""
struct RandomWalkPE{K} <: AbstractPositionalEncoding end

"""
    LaplacianPE{K}

Concrete type of positional encoding from graph Laplacian method.

See also [`positional_encode`](@ref) for generating positional encoding.
"""
struct LaplacianPE{K} <: AbstractPositionalEncoding end

"""
    positional_encode(RandomWalkPE{K}, A)

Returns positional encoding (PE) of size `(K, N)` where N is node number.
PE is generated by `K`-step random walk over given graph.

# Arguments

- `K::Int`: First dimension of PE.
- `A`: Adjacency matrix of a graph.

See also [`RandomWalkPE`](@ref) for random walk method.
"""
function positional_encode(::Type{RandomWalkPE{K}}, A::AbstractMatrix) where {K}
    N = size(A, 1)
    @assert K ≤ N "K=$K must less or equal to number of nodes ($N)"
    inv_D = GraphSignals.degree_matrix(A, Float32, inverse=true)

    RW = similar(A, size(A)..., K)
    RW[:, :, 1] .= A * inv_D
    for i in 2:K
        RW[:, :, i] .= RW[:, :, i-1] * RW[:, :, 1]
    end

    pe = similar(RW, K, N)
    for i in 1:N
        pe[:, i] .= RW[i, i, :]
    end

    return pe
end

"""
    positional_encode(LaplacianPE{K}, A)

Returns positional encoding (PE) of size `(K, N)` where `N` is node number.
PE is generated from eigenvectors of a graph Laplacian truncated by `K`.

# Arguments

- `K::Int`: First dimension of PE.
- `A`: Adjacency matrix of a graph.

See also [`LaplacianPE`](@ref) for graph Laplacian method.
"""
function positional_encode(::Type{LaplacianPE{K}}, A::AbstractMatrix) where {K}
    N = size(A, 1)
    @assert K ≤ N "K=$K must less or equal to number of nodes ($N)"
    L = GraphSignals.normalized_laplacian(A)
    U = eigvecs(L)
    return U[1:K, :]
end


"""
    EEquivGraphPE(in_dim=>out_dim; init=glorot_uniform, bias=true)

E(n)-equivariant positional encoding layer.

# Arguments

- `in_dim::Int`: dimension of input positional feature.
- `out_dim::Int`:  dimension of output positional feature.
- `init`: neural network initialization function.
- `bias::Bool`: dimension of edge feature.

# Examples

```jldoctest
julia> in_dim_edge, out_dim = 2, 5
(2, 5)

julia> l = EEquivGraphPE(in_dim_edge=>out_dim)
EEquivGraphPE(2 => 5)
```

See also [`EEquivGraphConv`](@ref).
"""
struct EEquivGraphPE{X} <: MessagePassing
    nn::X
end

function EEquivGraphPE(ch::Pair{Int,Int}; init=glorot_uniform, bias::Bool=true)
    in, out = ch
    nn = Flux.Dense(in, out; init=init, bias=bias)
    return EEquivGraphPE(nn)
end

@functor EEquivGraphPE

ϕ_x(l::EEquivGraphPE, m_ij) = l.nn(m_ij)

message(l::EEquivGraphPE, x_i, x_j, e) = (x_i - x_j) .* ϕ_x(l, e)

update(l::EEquivGraphPE, m::AbstractArray, x::AbstractArray) = m .+ x

# For variable graph
function(l::EEquivGraphPE)(fg::AbstractFeaturedGraph)
    X = node_feature(fg)
    E = edge_feature(fg)
    GraphSignals.check_num_nodes(fg, X)
    GraphSignals.check_num_nodes(fg, E)
    _, V, _ = propagate(l, graph(fg), E, X, nothing, mean, nothing, nothing)
    return ConcreteFeaturedGraph(fg, nf=V)
end

# For static graph
function(l::EEquivGraphPE)(el::NamedTuple, H::AbstractArray, E::AbstractArray)
    GraphSignals.check_num_nodes(el.N, H)
    # GraphSignals.check_num_edges(el.E, E)
    _, H, _ = propagate(l, el, E, H, nothing, mean, nothing, nothing)
    return H
end

(wg::WithGraph{<:EEquivGraphPE})(args...) = wg.layer(wg.graph, args...)

function Base.show(io::IO, l::EEquivGraphPE)
    print(io, "EEquivGraphPE(", input_dim(l), " => ", output_dim(l), ")")
end

input_dim(l::EEquivGraphPE) = size(l.nn.weight, 2)
output_dim(l::EEquivGraphPE) = size(l.nn.weight, 1)

positional_encode(wg::WithGraph{<:EEquivGraphPE}, args...) = wg(args...)
positional_encode(l::EEquivGraphPE, args...) = l(args...)


"""
    PositionalEncoding(graph, k; init_method=RandomWalkPE)

Positional encoding layer which adds learnable positional encoding to input data.

# Arguments

- `graph`: A given graph for positional encoding.
- `k::Int`: Dimension of positional encoding.
- `init_method`: Initializer for positional encoding.
"""
struct PositionalEncoding{P} <: AbstractPositionalEncoding
    pe::P
end

@functor PositionalEncoding

function PositionalEncoding(graph, k::Int; init_method=RandomWalkPE)
    fg = FeaturedGraph(graph)
    A = GraphSignals.adjacency_matrix(fg)
    pe = positional_encode(init_method{k}, A)
    return PositionalEncoding(pe)
end

positional_encode(l::PositionalEncoding) = l.pe

# For variable graph
function (l::PositionalEncoding)(fg::AbstractFeaturedGraph)
    if GraphSignals.has_positional_feature(fg)
        return fg
    else
        return ConcreteFeaturedGraph(fg, pf=positional_encode(l))
    end
end

Base.show(io::IO, l::PositionalEncoding) = print(io, "PositionalEncoding($(size(l.pe)))")


"""
    LSPE(f_h, f_e, f_p)

Learnable structural positional encoding layer.

# Arguments

- `f_h::MessagePassing`: Neural network layer for node update.
- `f_e`: Neural network layer for edge update.
- `f_p`: Neural network layer for positional encoding.
"""
struct LSPE{H<:MessagePassing,E,F} <: AbstractPositionalEncoding
    f_h::H
    f_e::E
    f_p::F
end

@functor LSPE

# For variable graph
function (l::LSPE)(fg::AbstractFeaturedGraph)
    H = node_feature(fg)
    E = edge_feature(fg)
    X = positional_feature(fg)
    GraphSignals.has_node_feature(fg) && GraphSignals.check_num_nodes(fg, H)
    GraphSignals.has_positional_feature(fg) && GraphSignals.check_num_nodes(fg, X)
    GraphSignals.has_edge_feature(fg) && GraphSignals.check_num_edges(fg, E)
    E, H, X = propagate(l, graph(fg), E, H, X)
    if isnothing(E)
        return ConcreteFeaturedGraph(fg, nf=H, pf=X)
    else
        return ConcreteFeaturedGraph(fg, nf=H, ef=E, pf=X)
    end
end

function (l::LSPE)(el::NamedTuple, H::AbstractArray, E::AbstractArray, X::AbstractArray)
    GraphSignals.check_num_nodes(el.N, H)
    GraphSignals.check_num_nodes(el.N, X)
    GraphSignals.check_num_edges(el.E, E)
    E, H, X = propagate(l, graph(fg), E, H, X)
    return H, E, X
end

update_vertex(l::LSPE, el::NamedTuple, H, E::AbstractArray) = l.f_h(el, H, E)
update_vertex(l::LSPE, el::NamedTuple, H, ::Nothing) = l.f_h(el, H)

update_edge(l::LSPE, h_i, h_j, e_ij) = l.f_e(e_ij)
update_edge(l::LSPE, h_i, h_j, ::Nothing) = l.f_e(vcat(h_i, h_j))

positional_encode(l::LSPE, p_i, p_j, e_ij) = l.f_p(p_i)

propagate(l::LSPE, sg::SparseGraph, E, H, X) =
    propagate(l, GraphSignals.to_namedtuple(sg), E, H, X)

function propagate(l::LSPE, el::NamedTuple, E, H, X)
    e_ij = _gather(E, el.es)
    h_i = _gather(H, el.xs)
    h_j = _gather(H, el.nbrs)
    p_i = _gather(X, el.xs)
    p_j = _gather(X, el.nbrs)

    H = update_vertex(l, el, vcat(H, X), E)
    E = update_edge(l, h_i, h_j, E)
    X = positional_encode(l, p_i, p_j, e_ij)
    return E, H, X
end

function propagate(l::LSPE, el::NamedTuple, ::Nothing, H, X)
    h_i = _gather(H, el.xs)
    h_j = _gather(H, el.nbrs)
    p_i = _gather(X, el.xs)
    p_j = _gather(X, el.nbrs)

    H = update_vertex(l, el, vcat(H, X), nothing)
    E = update_edge(l, h_i, h_j, nothing)
    X = positional_encode(l, p_i, p_j, nothing)
    return nothing, H, X
end

function Base.show(io::IO, l::LSPE)
    print(io, "LSPE(node_layer=", l.f_h)
    print(io, ", edge_layer=", l.f_e)
    print(io, ", positional_encode=", l.f_p, ")")
end
